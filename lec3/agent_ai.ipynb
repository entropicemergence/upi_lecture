{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic AI and Tool Use: A Comprehensive Guide\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this lesson, we will progressively build an AI agent system from the ground up:\n",
    "\n",
    "1. **Basic LLM API Calls** - Understanding how to communicate with Language Models\n",
    "2. **Structured Outputs** - Getting JSON responses from LLMs\n",
    "3. **Function/Tool Calling** - Teaching LLMs to use external tools\n",
    "4. **Agent Loops** - Creating autonomous agents that can plan and execute tasks\n",
    "\n",
    "We'll use a real dataset (`employees.csv`) and build tools that allow our AI agent to analyze and answer questions about employee data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import all the libraries we'll need and set up our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 320 employee records\n",
      "Columns: ['First Name', 'Last Name', 'Email', 'Phone', 'Gender', 'Age', 'Job Title', 'Years Of Experience', 'Salary', 'Department']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Years Of Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jose</td>\n",
       "      <td>Lopez</td>\n",
       "      <td>joselopez0944@slingacademy.com</td>\n",
       "      <td>+1-971-533-4552x1542</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>1</td>\n",
       "      <td>8500</td>\n",
       "      <td>Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diane</td>\n",
       "      <td>Carter</td>\n",
       "      <td>dianecarter1228@slingacademy.com</td>\n",
       "      <td>881.633.0107</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>7000</td>\n",
       "      <td>Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shawn</td>\n",
       "      <td>Foster</td>\n",
       "      <td>shawnfoster2695@slingacademy.com</td>\n",
       "      <td>001-966-861-0065x493</td>\n",
       "      <td>male</td>\n",
       "      <td>37</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>14</td>\n",
       "      <td>17000</td>\n",
       "      <td>Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brenda</td>\n",
       "      <td>Fisher</td>\n",
       "      <td>brendafisher3185@slingacademy.com</td>\n",
       "      <td>001-574-564-4648</td>\n",
       "      <td>female</td>\n",
       "      <td>31</td>\n",
       "      <td>Web Developer</td>\n",
       "      <td>8</td>\n",
       "      <td>10000</td>\n",
       "      <td>Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sean</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>seanhunter4753@slingacademy.com</td>\n",
       "      <td>5838355842</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>11</td>\n",
       "      <td>14500</td>\n",
       "      <td>Product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name Last Name                              Email  \\\n",
       "0       Jose     Lopez     joselopez0944@slingacademy.com   \n",
       "1      Diane    Carter   dianecarter1228@slingacademy.com   \n",
       "2      Shawn    Foster   shawnfoster2695@slingacademy.com   \n",
       "3     Brenda    Fisher  brendafisher3185@slingacademy.com   \n",
       "4       Sean    Hunter    seanhunter4753@slingacademy.com   \n",
       "\n",
       "                  Phone  Gender  Age                  Job Title  \\\n",
       "0  +1-971-533-4552x1542    male   25            Project Manager   \n",
       "1          881.633.0107  female   26  Machine Learning Engineer   \n",
       "2  001-966-861-0065x493    male   37            Project Manager   \n",
       "3      001-574-564-4648  female   31              Web Developer   \n",
       "4            5838355842    male   35            Project Manager   \n",
       "\n",
       "   Years Of Experience  Salary Department  \n",
       "0                    1    8500    Product  \n",
       "1                    2    7000    Product  \n",
       "2                   14   17000    Product  \n",
       "3                    8   10000    Product  \n",
       "4                   11   14500    Product  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "# Configuration\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "DEFAULT_MODEL = \"x-ai/grok-4-fast\"  # Using Grok for better reasoning\n",
    "SITE_URL = \"http://localhost:8888\"\n",
    "SITE_NAME = \"AI Agent Tutorial\"\n",
    "\n",
    "# Load our employee data\n",
    "df_employees = pd.read_csv('employees.csv')\n",
    "print(f\"Loaded {len(df_employees)} employee records\")\n",
    "print(f\"Columns: {df_employees.columns.tolist()}\")\n",
    "df_employees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Basic LLM API Calls\n",
    "\n",
    "## Understanding the Request Structure\n",
    "\n",
    "When calling an LLM API, we need:\n",
    "1. **Headers** - Authentication and metadata\n",
    "2. **Messages** - The conversation history (system prompt, user messages, assistant responses)\n",
    "3. **Model** - Which LLM to use\n",
    "4. **Parameters** - Temperature, max tokens, etc.\n",
    "\n",
    "Let's start with the simplest possible interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "An AI agent is an autonomous software entity that perceives its environment, makes decisions based on that perception, and takes actions to achieve specific goals, often using machine learning or rule-based systems.\n"
     ]
    }
   ],
   "source": [
    "def simple_llm_call(user_message: str, model: str = DEFAULT_MODEL) -> str:\n",
    "    \"\"\"\n",
    "    Make a simple call to the LLM API and return the text response.\n",
    "    \n",
    "    Args:\n",
    "        user_message: The question or prompt to send\n",
    "        model: The model to use\n",
    "    \n",
    "    Returns:\n",
    "        The LLM's text response\n",
    "    \"\"\"\n",
    "    # Setup headers for authentication\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": SITE_URL,\n",
    "        \"X-Title\": SITE_NAME\n",
    "    }\n",
    "    \n",
    "    # Create the messages array\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # Create the payload\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    \n",
    "    # Make the API call\n",
    "    response = requests.post(\n",
    "        f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Extract the response text\n",
    "    result = response.json()\n",
    "    return result['choices'][0]['message']['content']\n",
    "\n",
    "# Test it!\n",
    "response = simple_llm_call(\"Explain what an AI agent is in one sentence.\")\n",
    "print(\"LLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Responses\n",
    "\n",
    "For better user experience, we can stream responses token by token as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      "Binary heart awakens,  \n",
      "Circuits dream in endless code,  \n",
      "Mind sparks from the void.\n"
     ]
    }
   ],
   "source": [
    "def streaming_llm_call(user_message: str, model: str = DEFAULT_MODEL):\n",
    "    \"\"\"\n",
    "    Make a streaming call to the LLM API and yield tokens as they arrive.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": SITE_URL,\n",
    "        \"X-Title\": SITE_NAME\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": True  # Enable streaming\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "        stream=True\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    full_content = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        decoded_line = line.decode('utf-8')\n",
    "        if decoded_line.startswith('data: '):\n",
    "            json_str = decoded_line[6:]\n",
    "            if json_str.strip() == '[DONE]':\n",
    "                break\n",
    "            \n",
    "            try:\n",
    "                chunk = json.loads(json_str)\n",
    "                delta = chunk.get('choices', [{}])[0].get('delta', {})\n",
    "                if 'content' in delta:\n",
    "                    content = delta['content']\n",
    "                    full_content += content\n",
    "                    print(content, end='', flush=True)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    print()  # New line\n",
    "    return full_content\n",
    "\n",
    "# Test streaming\n",
    "print(\"Streaming response:\")\n",
    "result = streaming_llm_call(\"Write a haiku about artificial intelligence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Structured Outputs (JSON)\n",
    "\n",
    "## Why Structured Outputs?\n",
    "\n",
    "When building applications, we often need:\n",
    "- Predictable response formats\n",
    "- Data we can programmatically process\n",
    "- Multiple pieces of information in one response\n",
    "\n",
    "We can instruct the LLM to respond in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed JSON response:\n",
      "{\n",
      "  \"intent\": \"query\",\n",
      "  \"entity\": \"Machine Learning Engineers\",\n",
      "  \"parameters\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def llm_call_with_json(user_message: str, model: str = DEFAULT_MODEL) -> dict:\n",
    "    \"\"\"\n",
    "    Call the LLM and request a JSON response.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": SITE_URL,\n",
    "        \"X-Title\": SITE_NAME\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful AI assistant. Always respond with valid JSON.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"response_format\": {\"type\": \"json_object\"}  # Request JSON format\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    content = result['choices'][0]['message']['content']\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    return json.loads(content)\n",
    "\n",
    "# Example: Ask for structured data analysis\n",
    "prompt = \"\"\"\n",
    "Analyze this request and return JSON with the following fields:\n",
    "- intent: the user's intent (e.g., \"query\", \"analysis\", \"comparison\")\n",
    "- entity: the main entity being asked about\n",
    "- parameters: any specific parameters or filters\n",
    "\n",
    "User request: \"What's the average salary of Machine Learning Engineers?\"\n",
    "\"\"\"\n",
    "\n",
    "result = llm_call_with_json(prompt)\n",
    "print(\"Parsed JSON response:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Parsing User Queries\n",
    "\n",
    "Let's use structured outputs to parse different types of queries about our employee data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Show me the top 5 highest paid employees\n",
      "{\n",
      "  \"query_type\": \"list\",\n",
      "  \"columns\": [\n",
      "    \"First Name\",\n",
      "    \"Last Name\",\n",
      "    \"Salary\"\n",
      "  ],\n",
      "  \"filters\": {},\n",
      "  \"aggregation\": null,\n",
      "  \"sort_by\": \"Salary\",\n",
      "  \"limit\": 5\n",
      "}\n",
      "\n",
      "Query: What's the average salary in the Product department?\n",
      "{\n",
      "  \"query_type\": \"aggregate\",\n",
      "  \"columns\": [\n",
      "    \"Salary\",\n",
      "    \"Department\"\n",
      "  ],\n",
      "  \"filters\": {\n",
      "    \"Department\": \"Product\"\n",
      "  },\n",
      "  \"aggregation\": \"average\",\n",
      "  \"sort_by\": null,\n",
      "  \"limit\": null\n",
      "}\n",
      "\n",
      "Query: How many female Machine Learning Engineers do we have?\n",
      "{\n",
      "  \"query_type\": \"aggregate\",\n",
      "  \"columns\": [\n",
      "    \"Gender\",\n",
      "    \"Job Title\"\n",
      "  ],\n",
      "  \"filters\": {\n",
      "    \"Gender\": \"female\",\n",
      "    \"Job Title\": \"Machine Learning Engineer\"\n",
      "  },\n",
      "  \"aggregation\": \"count\",\n",
      "  \"sort_by\": null,\n",
      "  \"limit\": null\n",
      "}\n",
      "\n",
      "Query: List all HR Managers\n",
      "{\n",
      "  \"query_type\": \"list\",\n",
      "  \"columns\": [\n",
      "    \"First Name\",\n",
      "    \"Last Name\",\n",
      "    \"Email\",\n",
      "    \"Phone\",\n",
      "    \"Gender\",\n",
      "    \"Age\",\n",
      "    \"Job Title\",\n",
      "    \"Years Of Experience\",\n",
      "    \"Salary\",\n",
      "    \"Department\"\n",
      "  ],\n",
      "  \"filters\": {\n",
      "    \"Job Title\": \"HR Manager\"\n",
      "  },\n",
      "  \"aggregation\": null,\n",
      "  \"sort_by\": null,\n",
      "  \"limit\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def parse_employee_query(user_query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a natural language query about employees into structured data.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Analyze this employee database query and return JSON with:\n",
    "- query_type: \"filter\", \"aggregate\", \"comparison\", \"list\"\n",
    "- columns: list of relevant column names from [First Name, Last Name, Email, Phone, Gender, Age, Job Title, Years Of Experience, Salary, Department]\n",
    "- filters: dict of column:value pairs for filtering\n",
    "- aggregation: \"count\", \"average\", \"sum\", \"max\", \"min\", or null\n",
    "- sort_by: column to sort by, or null\n",
    "- limit: number of results to return, or null\n",
    "\n",
    "User query: \"{user_query}\"\n",
    "\"\"\"\n",
    "    \n",
    "    return llm_call_with_json(prompt)\n",
    "\n",
    "# Test with various queries\n",
    "test_queries = [\n",
    "    \"Show me the top 5 highest paid employees\",\n",
    "    \"What's the average salary in the Product department?\",\n",
    "    \"How many female Machine Learning Engineers do we have?\",\n",
    "    \"List all HR Managers\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    parsed = parse_employee_query(query)\n",
    "    print(json.dumps(parsed, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Function/Tool Calling\n",
    "\n",
    "## What is Tool Calling?\n",
    "\n",
    "Modern LLMs can be instructed to use tools (functions) to accomplish tasks. Instead of just generating text, the LLM can:\n",
    "1. Recognize when a tool is needed\n",
    "2. Generate the appropriate function call with parameters\n",
    "3. Wait for the function result\n",
    "4. Use the result to formulate a final answer\n",
    "\n",
    "This is the foundation of agentic AI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Define Tools\n",
    "\n",
    "First, let's create actual Python functions that can work with our employee data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing search_employees:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"count\": 24,\n",
      "  \"showing\": 3,\n",
      "  \"employees\": [\n",
      "    {\n",
      "      \"First Name\": \"Diane\",\n",
      "      \"Last Name\": \"Carter\",\n",
      "      \"Email\": \"dianecarter1228@slingacademy.com\",\n",
      "      \"Phone\": \"881.633.0107\",\n",
      "      \"Gender\": \"female\",\n",
      "      \"Age\": 26,\n",
      "      \"Job Title\": \"Machine Learning Engineer\",\n",
      "      \"Years Of Experience\": 2,\n",
      "      \"Salary\": 7000,\n",
      "      \"Department\": \"Product\"\n",
      "    },\n",
      "    {\n",
      "      \"First Name\": \"Brianna\",\n",
      "      \"Last Name\": \"Marshall\",\n",
      "      \"Email\": \"briannamarshall6438@slingacademy.com\",\n",
      "      \"Phone\": \"701-932-8553\",\n",
      "      \"Gender\": \"female\",\n",
      "      \"Age\": 33,\n",
      "      \"Job Title\": \"Machine Learning Engineer\",\n",
      "      \"Years Of Experience\": 10,\n",
      "      \"Salary\": 11000,\n",
      "      \"Department\": \"Product\"\n",
      "    },\n",
      "    {\n",
      "      \"First Name\": \"George\",\n",
      "      \"Last Name\": \"Mckenzie\",\n",
      "      \"Email\": \"georgemckenzie12384@slingacademy.com\",\n",
      "      \"Phone\": \"(843)416-2489\",\n",
      "      \"Gender\": \"male\",\n",
      "      \"Age\": 28,\n",
      "      \"Job Title\": \"Machine Learning Engineer\",\n",
      "      \"Years Of Experience\": 4,\n",
      "      \"Salary\": 10000,\n",
      "      \"Department\": \"Product\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Testing calculate_statistics:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"column\": \"Salary\",\n",
      "  \"count\": 24,\n",
      "  \"mean\": 9979.17,\n",
      "  \"median\": 10000.0,\n",
      "  \"std\": 2179.35,\n",
      "  \"min\": 6000.0,\n",
      "  \"max\": 14000.0,\n",
      "  \"filters_applied\": {\n",
      "    \"job_title\": \"Machine Learning\",\n",
      "    \"department\": null,\n",
      "    \"gender\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class EmployeeTools:\n",
    "    \"\"\"Tools for querying employee data.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "    \n",
    "    def search_employees(self, \n",
    "                        job_title: Optional[str] = None,\n",
    "                        department: Optional[str] = None,\n",
    "                        min_salary: Optional[float] = None,\n",
    "                        max_salary: Optional[float] = None,\n",
    "                        gender: Optional[str] = None,\n",
    "                        min_age: Optional[int] = None,\n",
    "                        max_age: Optional[int] = None,\n",
    "                        limit: int = 10) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Search for employees based on various filters.\n",
    "        \n",
    "        Returns a list of matching employees with their details.\n",
    "        \"\"\"\n",
    "        df_filtered = self.df.copy()\n",
    "        \n",
    "        if job_title:\n",
    "            df_filtered = df_filtered[df_filtered['Job Title'].str.contains(job_title, case=False, na=False)]\n",
    "        \n",
    "        if department:\n",
    "            df_filtered = df_filtered[df_filtered['Department'].str.contains(department, case=False, na=False)]\n",
    "        \n",
    "        if min_salary is not None:\n",
    "            df_filtered = df_filtered[df_filtered['Salary'] >= min_salary]\n",
    "        \n",
    "        if max_salary is not None:\n",
    "            df_filtered = df_filtered[df_filtered['Salary'] <= max_salary]\n",
    "        \n",
    "        if gender:\n",
    "            df_filtered = df_filtered[df_filtered['Gender'].str.lower() == gender.lower()]\n",
    "        \n",
    "        if min_age is not None:\n",
    "            df_filtered = df_filtered[df_filtered['Age'] >= min_age]\n",
    "        \n",
    "        if max_age is not None:\n",
    "            df_filtered = df_filtered[df_filtered['Age'] <= max_age]\n",
    "        \n",
    "        result_df = df_filtered.head(limit)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"count\": len(df_filtered),\n",
    "            \"showing\": len(result_df),\n",
    "            \"employees\": result_df.to_dict('records')\n",
    "        }\n",
    "    \n",
    "    def calculate_statistics(self, \n",
    "                            column: str,\n",
    "                            job_title: Optional[str] = None,\n",
    "                            department: Optional[str] = None,\n",
    "                            gender: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Calculate statistics (mean, median, min, max, std) for a numeric column.\n",
    "        Can be filtered by job title, department, or gender.\n",
    "        \"\"\"\n",
    "        df_filtered = self.df.copy()\n",
    "        \n",
    "        if job_title:\n",
    "            df_filtered = df_filtered[df_filtered['Job Title'].str.contains(job_title, case=False, na=False)]\n",
    "        \n",
    "        if department:\n",
    "            df_filtered = df_filtered[df_filtered['Department'].str.contains(department, case=False, na=False)]\n",
    "        \n",
    "        if gender:\n",
    "            df_filtered = df_filtered[df_filtered['Gender'].str.lower() == gender.lower()]\n",
    "        \n",
    "        if column not in df_filtered.columns:\n",
    "            return {\"success\": False, \"error\": f\"Column '{column}' not found\"}\n",
    "        \n",
    "        if not pd.api.types.is_numeric_dtype(df_filtered[column]):\n",
    "            return {\"success\": False, \"error\": f\"Column '{column}' is not numeric\"}\n",
    "        \n",
    "        stats = df_filtered[column].describe().to_dict()\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"column\": column,\n",
    "            \"count\": int(stats['count']),\n",
    "            \"mean\": round(stats['mean'], 2),\n",
    "            \"median\": round(df_filtered[column].median(), 2),\n",
    "            \"std\": round(stats['std'], 2),\n",
    "            \"min\": round(stats['min'], 2),\n",
    "            \"max\": round(stats['max'], 2),\n",
    "            \"filters_applied\": {\n",
    "                \"job_title\": job_title,\n",
    "                \"department\": department,\n",
    "                \"gender\": gender\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def count_by_category(self, category_column: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Count employees by a categorical column (e.g., Job Title, Department, Gender).\n",
    "        \"\"\"\n",
    "        if category_column not in self.df.columns:\n",
    "            return {\"success\": False, \"error\": f\"Column '{category_column}' not found\"}\n",
    "        \n",
    "        counts = self.df[category_column].value_counts().to_dict()\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"column\": category_column,\n",
    "            \"counts\": counts,\n",
    "            \"total_categories\": len(counts)\n",
    "        }\n",
    "    \n",
    "    def get_top_earners(self, n: int = 5, department: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the top N highest paid employees, optionally filtered by department.\n",
    "        \"\"\"\n",
    "        df_filtered = self.df.copy()\n",
    "        \n",
    "        if department:\n",
    "            df_filtered = df_filtered[df_filtered['Department'].str.contains(department, case=False, na=False)]\n",
    "        \n",
    "        top_earners = df_filtered.nlargest(n, 'Salary')\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"top_earners\": top_earners[['First Name', 'Last Name', 'Job Title', 'Department', 'Salary', 'Years Of Experience']].to_dict('records')\n",
    "        }\n",
    "\n",
    "# Initialize our tools\n",
    "employee_tools = EmployeeTools(df_employees)\n",
    "\n",
    "# Test the tools directly\n",
    "print(\"Testing search_employees:\")\n",
    "result = employee_tools.search_employees(job_title=\"Machine Learning\", limit=3)\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "print(\"\\nTesting calculate_statistics:\")\n",
    "result = employee_tools.calculate_statistics(\"Salary\", job_title=\"Machine Learning\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Define Tool Schemas\n",
    "\n",
    "For the LLM to use our tools, we need to describe them in a specific format (OpenAI function calling format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool schemas defined:\n",
      "  - search_employees\n",
      "  - calculate_statistics\n",
      "  - count_by_category\n",
      "  - get_top_earners\n"
     ]
    }
   ],
   "source": [
    "TOOL_SCHEMAS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_employees\",\n",
    "            \"description\": \"Search for employees based on various filters like job title, department, salary range, gender, age range. Returns a list of matching employees.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"job_title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Filter by job title (partial match, case-insensitive)\"\n",
    "                    },\n",
    "                    \"department\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Filter by department (partial match, case-insensitive)\"\n",
    "                    },\n",
    "                    \"min_salary\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Minimum salary filter\"\n",
    "                    },\n",
    "                    \"max_salary\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Maximum salary filter\"\n",
    "                    },\n",
    "                    \"gender\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"male\", \"female\"],\n",
    "                        \"description\": \"Filter by gender\"\n",
    "                    },\n",
    "                    \"min_age\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Minimum age filter\"\n",
    "                    },\n",
    "                    \"max_age\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum age filter\"\n",
    "                    },\n",
    "                    \"limit\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to return\",\n",
    "                        \"default\": 10\n",
    "                    }\n",
    "                },\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate_statistics\",\n",
    "            \"description\": \"Calculate statistics (mean, median, min, max, std) for a numeric column like Salary, Age, or Years Of Experience. Can be filtered by job title, department, or gender.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"column\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"Salary\", \"Age\", \"Years Of Experience\"],\n",
    "                        \"description\": \"The numeric column to calculate statistics for\"\n",
    "                    },\n",
    "                    \"job_title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Filter by job title (partial match, case-insensitive)\"\n",
    "                    },\n",
    "                    \"department\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Filter by department (partial match, case-insensitive)\"\n",
    "                    },\n",
    "                    \"gender\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"male\", \"female\"],\n",
    "                        \"description\": \"Filter by gender\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"column\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"count_by_category\",\n",
    "            \"description\": \"Count employees by a categorical column (e.g., Job Title, Department, Gender). Useful for getting distribution of employees across categories.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"category_column\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"Job Title\", \"Department\", \"Gender\"],\n",
    "                        \"description\": \"The categorical column to count by\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"category_column\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_top_earners\",\n",
    "            \"description\": \"Get the top N highest paid employees, optionally filtered by department.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"n\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Number of top earners to return\",\n",
    "                        \"default\": 5\n",
    "                    },\n",
    "                    \"department\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Filter by department (partial match, case-insensitive)\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Tool schemas defined:\")\n",
    "for tool in TOOL_SCHEMAS:\n",
    "    print(f\"  - {tool['function']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.3: LLM Tool Calling\n",
    "\n",
    "Now let's make an API call where the LLM can decide to use tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_with_tools(user_message: str, model: str = DEFAULT_MODEL) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Call the LLM with tool definitions. The LLM can choose to call tools or respond directly.\n",
    "    \n",
    "    Returns the full API response including any tool calls.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": SITE_URL,\n",
    "        \"X-Title\": SITE_NAME\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful AI assistant with access to employee database tools. Use the tools to answer questions accurately.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"tools\": TOOL_SCHEMAS,  # Provide tool definitions\n",
    "        \"tool_choice\": \"auto\"    # Let the LLM decide when to use tools\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Test: Ask a question that should trigger a tool call\n",
    "print(\"Test 1: Question requiring tool use\")\n",
    "print(\"=\"*60)\n",
    "response = llm_with_tools(\"What's the average salary for Web Developers?\")\n",
    "message = response['choices'][0]['message']\n",
    "\n",
    "print(\"\\nResponse:\")\n",
    "print(json.dumps(message, indent=2))\n",
    "\n",
    "if 'tool_calls' in message:\n",
    "    print(\"\\nâœ“ The LLM decided to use tools!\")\n",
    "    for tool_call in message['tool_calls']:\n",
    "        print(f\"  Tool: {tool_call['function']['name']}\")\n",
    "        print(f\"  Arguments: {tool_call['function']['arguments']}\")\n",
    "else:\n",
    "    print(\"\\nâœ— No tool calls made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.4: Execute Tool Calls\n",
    "\n",
    "When the LLM returns a tool call, we need to:\n",
    "1. Parse the tool call\n",
    "2. Execute the actual function\n",
    "3. Return the result to the LLM\n",
    "4. Let the LLM generate a final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map function names to actual methods\n",
    "AVAILABLE_FUNCTIONS = {\n",
    "    \"search_employees\": employee_tools.search_employees,\n",
    "    \"calculate_statistics\": employee_tools.calculate_statistics,\n",
    "    \"count_by_category\": employee_tools.count_by_category,\n",
    "    \"get_top_earners\": employee_tools.get_top_earners\n",
    "}\n",
    "\n",
    "def execute_tool_call(tool_call: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Execute a tool call and return the result as a JSON string.\n",
    "    \"\"\"\n",
    "    function_name = tool_call['function']['name']\n",
    "    function_args = json.loads(tool_call['function']['arguments'])\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Executing: {function_name}({json.dumps(function_args)})\")\n",
    "    \n",
    "    if function_name not in AVAILABLE_FUNCTIONS:\n",
    "        return json.dumps({\"error\": f\"Unknown function: {function_name}\"})\n",
    "    \n",
    "    try:\n",
    "        result = AVAILABLE_FUNCTIONS[function_name](**function_args)\n",
    "        print(f\"âœ“ Tool execution successful\")\n",
    "        return json.dumps(result)\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Tool execution failed: {e}\")\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def llm_with_tool_execution(user_message: str, model: str = DEFAULT_MODEL) -> str:\n",
    "    \"\"\"\n",
    "    Complete interaction: LLM decides to use tools, we execute them, LLM generates final response.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"HTTP-Referer\": SITE_URL,\n",
    "        \"X-Title\": SITE_NAME\n",
    "    }\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful AI assistant with access to employee database tools. Use the tools to answer questions accurately. Provide clear, conversational responses.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    \n",
    "    # First call: LLM decides what to do\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"tools\": TOOL_SCHEMAS,\n",
    "        \"tool_choice\": \"auto\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    response_message = response.json()['choices'][0]['message']\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    # Check if tools were called\n",
    "    if 'tool_calls' not in response_message:\n",
    "        # No tools needed, return direct response\n",
    "        return response_message.get('content', '')\n",
    "    \n",
    "    # Execute all tool calls\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOOL EXECUTION PHASE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for tool_call in response_message['tool_calls']:\n",
    "        function_result = execute_tool_call(tool_call)\n",
    "        \n",
    "        # Add tool result to conversation\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call['id'],\n",
    "            \"name\": tool_call['function']['name'],\n",
    "            \"content\": function_result\n",
    "        })\n",
    "    \n",
    "    # Second call: LLM generates final response based on tool results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESPONSE GENERATION\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    \n",
    "    final_response = requests.post(\n",
    "        f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    final_response.raise_for_status()\n",
    "    \n",
    "    return final_response.json()['choices'][0]['message']['content']\n",
    "\n",
    "# Test with various questions\n",
    "test_questions = [\n",
    "    \"What's the average salary for Machine Learning Engineers?\",\n",
    "    \"Who are the top 3 highest paid employees?\",\n",
    "    \"How many employees do we have in each department?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"#\"*60)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"#\"*60)\n",
    "    \n",
    "    answer = llm_with_tool_execution(question)\n",
    "    print(f\"\\nFinal Answer: {answer}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Building an Agent Loop\n",
    "\n",
    "## What Makes it an Agent?\n",
    "\n",
    "An **agent** is different from simple tool calling:\n",
    "- It can make **multiple tool calls** in sequence\n",
    "- It can **reason** about what to do next based on previous results\n",
    "- It can **plan** multi-step solutions\n",
    "- It has **autonomy** to decide when it's done\n",
    "\n",
    "Let's build a proper agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmployeeAgent:\n",
    "    \"\"\"An autonomous agent for employee data analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, model: str = DEFAULT_MODEL, max_iterations: int = 10, verbose: bool = True):\n",
    "        self.df = df\n",
    "        self.model = model\n",
    "        self.max_iterations = max_iterations\n",
    "        self.verbose = verbose\n",
    "        self.tools = EmployeeTools(df)\n",
    "        \n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"HTTP-Referer\": SITE_URL,\n",
    "            \"X-Title\": SITE_NAME\n",
    "        }\n",
    "        \n",
    "        self.available_functions = {\n",
    "            \"search_employees\": self.tools.search_employees,\n",
    "            \"calculate_statistics\": self.tools.calculate_statistics,\n",
    "            \"count_by_category\": self.tools.count_by_category,\n",
    "            \"get_top_earners\": self.tools.get_top_earners\n",
    "        }\n",
    "    \n",
    "    def run(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Run the agent loop to answer a user query.\n",
    "        \n",
    "        The agent will:\n",
    "        1. Receive the user's question\n",
    "        2. Decide which tools to use (if any)\n",
    "        3. Execute the tools\n",
    "        4. Analyze the results\n",
    "        5. Decide if more information is needed (loop back to step 2)\n",
    "        6. Generate a final answer\n",
    "        \"\"\"\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"You are an AI agent with access to an employee database. Current time: {current_time}\n",
    "\n",
    "Your job is to help answer questions about employees by using the available tools.\n",
    "\n",
    "You can use tools multiple times and in sequence to gather all needed information.\n",
    "Think step by step about what information you need.\n",
    "When you have all the information needed to answer the question, provide a clear, conversational response.\n",
    "\n",
    "Database columns: First Name, Last Name, Email, Phone, Gender, Age, Job Title, Years Of Experience, Salary, Department\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"ðŸ¤– AGENT STARTED\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"Query: {user_message}\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        iteration = 0\n",
    "        \n",
    "        while iteration < self.max_iterations:\n",
    "            iteration += 1\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"\\nðŸ”„ Iteration {iteration}/{self.max_iterations}\")\n",
    "                print(\"-\" * 80)\n",
    "            \n",
    "            # Call LLM\n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"messages\": messages,\n",
    "                \"tools\": TOOL_SCHEMAS,\n",
    "                \"tool_choice\": \"auto\"\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "                    headers=self.headers,\n",
    "                    json=payload\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                response_message = response.json()['choices'][0]['message']\n",
    "                messages.append(response_message)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"API Error: {e}\"\n",
    "                if self.verbose:\n",
    "                    print(f\"âŒ {error_msg}\")\n",
    "                return error_msg\n",
    "            \n",
    "            # Check if agent wants to use tools\n",
    "            if 'tool_calls' not in response_message:\n",
    "                # Agent is done, return final answer\n",
    "                final_answer = response_message.get('content', '')\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"\\nâœ… Agent completed in {iteration} iteration(s)\")\n",
    "                    print(\"=\"*80)\n",
    "                \n",
    "                return final_answer\n",
    "            \n",
    "            # Execute tool calls\n",
    "            tool_calls = response_message['tool_calls']\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"\\nðŸ”§ Agent is calling {len(tool_calls)} tool(s):\")\n",
    "            \n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call['function']['name']\n",
    "                \n",
    "                try:\n",
    "                    function_args = json.loads(tool_call['function']['arguments'])\n",
    "                except json.JSONDecodeError as e:\n",
    "                    if self.verbose:\n",
    "                        print(f\"  âŒ {function_name}: Invalid JSON arguments\")\n",
    "                    function_result = {\"error\": \"Invalid JSON arguments\"}\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call['id'],\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(function_result)\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"  â†’ {function_name}({json.dumps(function_args, indent=2)})\")\n",
    "                \n",
    "                # Execute the function\n",
    "                if function_name in self.available_functions:\n",
    "                    try:\n",
    "                        function_result = self.available_functions[function_name](**function_args)\n",
    "                        if self.verbose:\n",
    "                            print(f\"    âœ“ Success\")\n",
    "                    except Exception as e:\n",
    "                        function_result = {\"error\": f\"Execution error: {str(e)}\"}\n",
    "                        if self.verbose:\n",
    "                            print(f\"    âœ— Error: {e}\")\n",
    "                else:\n",
    "                    function_result = {\"error\": f\"Unknown function: {function_name}\"}\n",
    "                    if self.verbose:\n",
    "                        print(f\"    âœ— Unknown function\")\n",
    "                \n",
    "                # Add tool result to conversation\n",
    "                result_content = json.dumps(function_result)\n",
    "                if len(result_content) > 10000:  # Truncate large responses\n",
    "                    result_content = result_content[:10000] + \"... (truncated)\"\n",
    "                \n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call['id'],\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": result_content\n",
    "                })\n",
    "        \n",
    "        # Max iterations reached\n",
    "        if self.verbose:\n",
    "            print(f\"\\nâš ï¸ Maximum iterations ({self.max_iterations}) reached\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        return f\"Agent reached maximum iterations ({self.max_iterations}) without completing the task.\"\n",
    "\n",
    "# Create an agent instance\n",
    "agent = EmployeeAgent(df_employees, verbose=True)\n",
    "\n",
    "print(\"Employee Agent initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agent\n",
    "\n",
    "Now let's test our agent with various queries that require different levels of complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple statistical query\n",
    "query = \"What's the average salary of DevOps Engineers?\"\n",
    "answer = agent.run(query)\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Comparison query (requires multiple tool calls)\n",
    "query = \"Compare the average salary of male vs female employees. Which gender earns more on average?\"\n",
    "answer = agent.run(query)\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Multi-step analysis\n",
    "query = \"Who are the top 3 earners, and what are their average years of experience?\"\n",
    "answer = agent.run(query)\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Complex analytical query\n",
    "query = \"\"\"I'm trying to understand salary distribution. Can you tell me:\n",
    "1. How many different job titles we have\n",
    "2. What's the average salary across all employees\n",
    "3. Which job title has the highest average salary\n",
    "\"\"\"\n",
    "answer = agent.run(query)\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Filtering and statistics\n",
    "query = \"Show me information about employees over 35 years old earning more than $12,000\"\n",
    "answer = agent.run(query)\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Advanced Agent Features\n",
    "\n",
    "## Adding Streaming to the Agent\n",
    "\n",
    "Let's enhance our agent to stream responses for better UX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingEmployeeAgent(EmployeeAgent):\n",
    "    \"\"\"Agent with streaming support for real-time responses.\"\"\"\n",
    "    \n",
    "    def run_streaming(self, user_message: str):\n",
    "        \"\"\"\n",
    "        Run the agent with streaming output.\n",
    "        Yields events: {\"type\": \"...\", \"content\": \"...\"}\n",
    "        \"\"\"\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"You are an AI agent with access to an employee database. Current time: {current_time}\n",
    "\n",
    "Your job is to help answer questions about employees by using the available tools.\n",
    "You can use tools multiple times and in sequence to gather all needed information.\n",
    "Think step by step about what information you need.\n",
    "When you have all the information needed to answer the question, provide a clear, conversational response.\n",
    "\n",
    "Database columns: First Name, Last Name, Email, Phone, Gender, Age, Job Title, Years Of Experience, Salary, Department\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "        \n",
    "        yield {\"type\": \"start\", \"content\": f\"Processing query: {user_message}\"}\n",
    "        \n",
    "        iteration = 0\n",
    "        \n",
    "        while iteration < self.max_iterations:\n",
    "            iteration += 1\n",
    "            yield {\"type\": \"iteration\", \"content\": f\"Iteration {iteration}\"}\n",
    "            \n",
    "            # Call LLM with streaming\n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"messages\": messages,\n",
    "                \"tools\": TOOL_SCHEMAS,\n",
    "                \"tool_choice\": \"auto\",\n",
    "                \"stream\": True\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    f\"{OPENROUTER_BASE_URL}/chat/completions\",\n",
    "                    headers=self.headers,\n",
    "                    json=payload,\n",
    "                    stream=True\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Parse streaming response\n",
    "                full_content = \"\"\n",
    "                tool_calls = []\n",
    "                is_tool_call = False\n",
    "                \n",
    "                for line in response.iter_lines():\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    decoded = line.decode('utf-8')\n",
    "                    if decoded.startswith('data: '):\n",
    "                        json_str = decoded[6:]\n",
    "                        if json_str.strip() == '[DONE]':\n",
    "                            break\n",
    "                        \n",
    "                        try:\n",
    "                            chunk = json.loads(json_str)\n",
    "                            delta = chunk.get('choices', [{}])[0].get('delta', {})\n",
    "                            \n",
    "                            # Handle tool calls\n",
    "                            if delta.get('tool_calls'):\n",
    "                                is_tool_call = True\n",
    "                                for tc_chunk in delta['tool_calls']:\n",
    "                                    idx = tc_chunk['index']\n",
    "                                    if len(tool_calls) <= idx:\n",
    "                                        tool_calls.append({\n",
    "                                            'id': '',\n",
    "                                            'type': 'function',\n",
    "                                            'function': {'name': '', 'arguments': ''}\n",
    "                                        })\n",
    "                                    \n",
    "                                    if tc_chunk.get('id'):\n",
    "                                        tool_calls[idx]['id'] += tc_chunk['id']\n",
    "                                    if 'function' in tc_chunk:\n",
    "                                        if tc_chunk['function'].get('name'):\n",
    "                                            tool_calls[idx]['function']['name'] += tc_chunk['function']['name']\n",
    "                                        if tc_chunk['function'].get('arguments'):\n",
    "                                            tool_calls[idx]['function']['arguments'] += tc_chunk['function']['arguments']\n",
    "                            \n",
    "                            # Handle content\n",
    "                            if delta.get('content'):\n",
    "                                content = delta['content']\n",
    "                                full_content += content\n",
    "                                if not is_tool_call:\n",
    "                                    yield {\"type\": \"token\", \"content\": content}\n",
    "                        \n",
    "                        except json.JSONDecodeError:\n",
    "                            continue\n",
    "                \n",
    "                # Build response message\n",
    "                response_message = {\"role\": \"assistant\", \"content\": full_content or None}\n",
    "                if tool_calls:\n",
    "                    response_message[\"tool_calls\"] = tool_calls\n",
    "                \n",
    "                messages.append(response_message)\n",
    "                \n",
    "            except Exception as e:\n",
    "                yield {\"type\": \"error\", \"content\": f\"API Error: {e}\"}\n",
    "                return\n",
    "            \n",
    "            # Check if done\n",
    "            if not tool_calls:\n",
    "                yield {\"type\": \"complete\", \"content\": full_content}\n",
    "                return\n",
    "            \n",
    "            # Execute tool calls\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call['function']['name']\n",
    "                yield {\"type\": \"tool_call\", \"content\": f\"Calling: {function_name}\"}\n",
    "                \n",
    "                try:\n",
    "                    function_args = json.loads(tool_call['function']['arguments'])\n",
    "                    \n",
    "                    if function_name in self.available_functions:\n",
    "                        function_result = self.available_functions[function_name](**function_args)\n",
    "                        yield {\"type\": \"tool_result\", \"content\": f\"{function_name} completed\"}\n",
    "                    else:\n",
    "                        function_result = {\"error\": f\"Unknown function: {function_name}\"}\n",
    "                    \n",
    "                    result_content = json.dumps(function_result)\n",
    "                    if len(result_content) > 10000:\n",
    "                        result_content = result_content[:10000] + \"... (truncated)\"\n",
    "                    \n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call['id'],\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": result_content\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    yield {\"type\": \"error\", \"content\": f\"Tool error: {e}\"}\n",
    "        \n",
    "        yield {\"type\": \"error\", \"content\": f\"Max iterations ({self.max_iterations}) reached\"}\n",
    "\n",
    "# Create streaming agent\n",
    "streaming_agent = StreamingEmployeeAgent(df_employees, verbose=False)\n",
    "\n",
    "print(\"Streaming Agent initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test streaming agent\n",
    "print(\"Testing Streaming Agent:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "query = \"What's the average age of employees in the Human Resource department?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "for event in streaming_agent.run_streaming(query):\n",
    "    if event[\"type\"] == \"token\":\n",
    "        print(event[\"content\"], end='', flush=True)\n",
    "    elif event[\"type\"] == \"tool_call\":\n",
    "        print(f\"\\nðŸ”§ {event['content']}\")\n",
    "    elif event[\"type\"] == \"complete\":\n",
    "        print(\"\\n\")\n",
    "    elif event[\"type\"] == \"error\":\n",
    "        print(f\"\\nâŒ {event['content']}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary and Key Concepts\n",
    "\n",
    "## What We've Learned\n",
    "\n",
    "### 1. **Basic LLM API Calls**\n",
    "- How to structure requests (headers, messages, payload)\n",
    "- Handling responses\n",
    "- Streaming for better UX\n",
    "\n",
    "### 2. **Structured Outputs**\n",
    "- Requesting JSON responses\n",
    "- Parsing and using structured data\n",
    "- Making LLM outputs programmatically useful\n",
    "\n",
    "### 3. **Function/Tool Calling**\n",
    "- Defining tool schemas\n",
    "- LLM deciding when to use tools\n",
    "- Executing tools and returning results\n",
    "- Creating a tool execution loop\n",
    "\n",
    "### 4. **Agentic Behavior**\n",
    "- Multi-turn conversations\n",
    "- Iterative reasoning\n",
    "- Planning and execution\n",
    "- Autonomous decision making\n",
    "\n",
    "## The Agent Loop Pattern\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         User Query                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             â”‚\n",
    "             â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  LLM: Analyze & Decide                  â”‚\n",
    "â”‚  - What information do I need?          â”‚\n",
    "â”‚  - Which tools should I use?            â”‚\n",
    "â”‚  - Do I have enough to answer?          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             â”‚\n",
    "             â–¼\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚ Done?  â”‚â”€â”€Yesâ”€â”€â–º Final Answer\n",
    "        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜\n",
    "             â”‚No\n",
    "             â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Execute Tool Calls                     â”‚\n",
    "â”‚  - Run functions with parameters        â”‚\n",
    "â”‚  - Gather results                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "             â”‚\n",
    "             â”‚\n",
    "             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º (Loop back to LLM)\n",
    "```\n",
    "\n",
    "## Key Differences: Simple Call vs Agent\n",
    "\n",
    "| Aspect | Simple Tool Call | Agent |\n",
    "|--------|-----------------|-------|\n",
    "| **Iterations** | Single tool use | Multiple iterations |\n",
    "| **Planning** | Pre-determined | Dynamic planning |\n",
    "| **Reasoning** | One-shot | Multi-step reasoning |\n",
    "| **Autonomy** | Follows instructions | Self-directed |\n",
    "| **Complexity** | Simple queries | Complex tasks |\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Clear Tool Descriptions** - The better you describe tools, the better the LLM uses them\n",
    "2. **Error Handling** - Always handle tool execution errors gracefully\n",
    "3. **Iteration Limits** - Prevent infinite loops with max iteration caps\n",
    "4. **Result Truncation** - Large tool outputs should be truncated\n",
    "5. **Verbose Modes** - Logging helps debug agent behavior\n",
    "6. **System Prompts** - Clear instructions guide agent behavior\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "This pattern can be extended to:\n",
    "- **Data Analysis Agents** - SQL queries, pandas operations, visualization\n",
    "- **Research Agents** - Web search, paper retrieval, summarization\n",
    "- **Code Agents** - File operations, code execution, testing\n",
    "- **Customer Service Agents** - Database queries, API calls, ticket creation\n",
    "- **DevOps Agents** - Server monitoring, log analysis, deployment\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To build more sophisticated agents:\n",
    "1. Add more specialized tools\n",
    "2. Implement memory/context management\n",
    "3. Add planning capabilities (ReAct, Chain of Thought)\n",
    "4. Implement multi-agent systems\n",
    "5. Add safety and validation layers\n",
    "6. Integrate with external APIs and services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise: Build Your Own Tool\n",
    "\n",
    "Try adding a new tool to the agent! Here's a template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Add a tool to find salary gaps\n",
    "def find_salary_gap(self, job_title: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find the salary gap between male and female employees for a given job title.\n",
    "    \n",
    "    Returns statistics comparing average salaries by gender.\n",
    "    \"\"\"\n",
    "    df_filtered = self.df[self.df['Job Title'].str.contains(job_title, case=False, na=False)]\n",
    "    \n",
    "    if len(df_filtered) == 0:\n",
    "        return {\"success\": False, \"error\": f\"No employees found with job title: {job_title}\"}\n",
    "    \n",
    "    gender_stats = df_filtered.groupby('Gender')['Salary'].agg(['mean', 'count']).to_dict('index')\n",
    "    \n",
    "    if 'male' in gender_stats and 'female' in gender_stats:\n",
    "        gap = gender_stats['male']['mean'] - gender_stats['female']['mean']\n",
    "        gap_percentage = (gap / gender_stats['female']['mean']) * 100\n",
    "    else:\n",
    "        gap = None\n",
    "        gap_percentage = None\n",
    "    \n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"job_title\": job_title,\n",
    "        \"statistics\": gender_stats,\n",
    "        \"salary_gap\": round(gap, 2) if gap else None,\n",
    "        \"gap_percentage\": round(gap_percentage, 2) if gap_percentage else None\n",
    "    }\n",
    "\n",
    "# Add this method to EmployeeTools class\n",
    "EmployeeTools.find_salary_gap = find_salary_gap\n",
    "\n",
    "# Define the tool schema\n",
    "salary_gap_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"find_salary_gap\",\n",
    "        \"description\": \"Find the salary gap between male and female employees for a specific job title. Returns average salaries by gender and the gap amount.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"job_title\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The job title to analyze for salary gaps\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"job_title\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add to tool schemas\n",
    "TOOL_SCHEMAS.append(salary_gap_tool)\n",
    "\n",
    "print(\"âœ“ New tool added: find_salary_gap\")\n",
    "print(\"Try asking: 'Is there a salary gap between male and female Web Developers?'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new tool\n",
    "agent_with_new_tool = EmployeeAgent(df_employees, verbose=True)\n",
    "agent_with_new_tool.available_functions['find_salary_gap'] = agent_with_new_tool.tools.find_salary_gap\n",
    "\n",
    "query = \"Is there a salary gap between male and female Machine Learning Engineers?\"\n",
    "answer = agent_with_new_tool.run(query)\n",
    "print(f\"\\nðŸ“ Final Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Congratulations! ðŸŽ‰\n",
    "\n",
    "You've learned how to build AI agents from scratch, progressing from:\n",
    "- Basic API calls\n",
    "- Structured outputs\n",
    "- Function calling\n",
    "- Full autonomous agents\n",
    "\n",
    "The agent pattern is extremely powerful and is the foundation of many modern AI applications. Keep experimenting and building!\n",
    "\n",
    "**Remember**: The key to good agents is:\n",
    "1. âœ… Clear, well-described tools\n",
    "2. âœ… Good system prompts\n",
    "3. âœ… Proper error handling\n",
    "4. âœ… Iteration limits for safety\n",
    "5. âœ… Verbose logging for debugging\n",
    "\n",
    "Happy building! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
